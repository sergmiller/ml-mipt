{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergmiller/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sps\n",
    "plt.style.use('ggplot')\n",
    "from sympy import *\n",
    "import copy\n",
    "from matplotlib import cm\n",
    "from scipy import sparse\n",
    "import scipy.sparse as sprs\n",
    "from sklearn.svm import SVC\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "row_train = pd.read_csv('linear_train.txt',header=-1)\n",
    "row_test = pd.read_csv('linear_test.txt',header=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Аалтонен</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Аар</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Аарон</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ААРОН</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Аарона</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  1\n",
       "0  Аалтонен  1\n",
       "1       Аар  0\n",
       "2     Аарон  0\n",
       "3     ААРОН  0\n",
       "4    Аарона  0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Аалто</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ААР</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Аара</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ааре</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Аарон</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  Аалто\n",
       "1    ААР\n",
       "2   Аара\n",
       "3   Ааре\n",
       "4  Аарон"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_column(frame, data, names):\n",
    "    new_fr = pd.DataFrame(data, columns=names)\n",
    "    return pd.concat((frame, new_fr),axis=1)\n",
    "\n",
    "def gen_suffixes(frame, slen):\n",
    "    suff = set()\n",
    "    for w in frame[0]:\n",
    "        for l in range(1,slen+1):\n",
    "            suff.add(w[-l:])\n",
    "    return suff\n",
    "\n",
    "def add_strs(frame,suffixes=None):\n",
    "    if suffixes is None:\n",
    "        suffixes = gen_suffixes(frame)\n",
    "#     for suff in suffixes:\n",
    "    suffixes_set = suffixes\n",
    "    suffixes = list(suffixes)\n",
    "    data = np.zeros((len(frame[0]),len(suffixes)))\n",
    "    numb = {suffixes[i]:i for i in range(len(suffixes))}\n",
    "    strs = frame[0]\n",
    "    for i in range(len(strs)):\n",
    "        for k in range(len(strs[i])):\n",
    "            for j in range(2):\n",
    "                suff = strs[i][k:]\n",
    "                if j > 0 and len(suff) > 1:\n",
    "                    suff = suff[:-1]\n",
    "                if suff in suffixes_set:\n",
    "                    cur = numb[suff]\n",
    "                    data[i][cur] = 1\n",
    "    frame = add_column(frame, data, suffixes)\n",
    "    frame = frame.drop([0],axis=1)\n",
    "    if 1 in frame.columns:\n",
    "        frame = frame.drop([1],axis=1)\n",
    "    return sprs.coo_matrix(frame), suffixes_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_custom(frame, f, name):\n",
    "    data = np.array([f(x) for x in frame[0]]).reshape((len(frame[0]),1))\n",
    "    return add_column(frame, data, [name])\n",
    "\n",
    "def normalize(frame, name):\n",
    "    frame[name] = (np.array(frame[name]) - np.mean(frame[name]))/np.std(frame[name])\n",
    "    return frame\n",
    "\n",
    "def clear(train, test):\n",
    "    lenn = len(train[0])\n",
    "    for c in test.columns:\n",
    "        if c != 0:\n",
    "            summ = np.sum(np.array(train[c]))\n",
    "            if summ == lenn or summ == 0:\n",
    "                train = train.drop([c], axis=1)\n",
    "                test = test.drop([c],axis=1)\n",
    "    return train, test\n",
    "\n",
    "def normalize_all(train, test):\n",
    "    for c in test.columns:\n",
    "        if c != 0:\n",
    "            arr = np.array(train[c])\n",
    "            m = np.mean(arr)\n",
    "            s = np.std(arr)\n",
    "            train[c] = (train[c] - m)/s\n",
    "            test[c] = (test[c] - m)/s\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.3 s, sys: 9.1 s, total: 41.4 s\n",
      "Wall time: 42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(row_train[0])):\n",
    "    s = row_train[0][i]\n",
    "    if row_train[1][i] == 1:\n",
    "        if s[-1] == 'а' and len(s) > 1:\n",
    "            row_train.loc[len(row_train[0])]=([s[:-1],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101403</th>\n",
       "      <td>Ёлкин</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101404</th>\n",
       "      <td>ёлкой</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101405</th>\n",
       "      <td>ёлок</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101406</th>\n",
       "      <td>ёлочкой</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101407</th>\n",
       "      <td>ёмкость</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  1\n",
       "101403    Ёлкин  1\n",
       "101404    ёлкой  0\n",
       "101405     ёлок  0\n",
       "101406  ёлочкой  0\n",
       "101407  ёмкость  0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_count_vectorizer_features(train, test):\n",
    "    vectorizer = CountVectorizer(min_df=5, max_df=.7,\n",
    "                             max_features=None,\n",
    "                             ngram_range=(3, 5),\n",
    "                             lowercase=False,\n",
    "                             analyzer='char_wb', \n",
    "                             binary=True)\n",
    "    TTrainM = vectorizer.fit_transform(train[0])\n",
    "    TTestM = vectorizer.transform(test[0])\n",
    "    return TTrainM, TTestM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['лда', 'нкс', 'скую', 'соны', 'хэм', 'рри', 'рма', 'арда', 'ачев', 'вским', 'длер', 'дман', 'еева', 'иковым', 'инског', 'инского', 'йлс', 'йтс', 'киным', 'мова', 'мову', 'никова', 'АН', 'кове', 'ттер', 'ейном', 'есом', 'вино', 'ису', 'ейр', 'кину', 'рре', 'рсоно', 'вел', 'рса', 'рон', 'лером', 'йер', 'яков', 'ре', 'ейт', 'ких', 'енберг', 'йнс', 'сонов', 'тман', 'эя', 'ейл', 'ди', 'мсо', 'ских', 'улин', 'ас', 'ановы', 'ерсом', 'ровым', 'ерто', 'арев', 'арр', 'гг', 'инсо', 'кую', 'рер', 'соне', 'ран', 'евски', 'енский', 'нской', 'нсона', 'ткин', 'нз', 'йту', 'ллин', 'лто', 'леро', 'им', 'рро', 'рис', 'ено', 'ауэр', 'бин', 'НА', 'нском', 'сену', 'тсо', 'ерн', 'рин', 'вском', 'йтон', 'ковых', 'овской', 'сена', 'ттом', 'янов', 'дин', 'вская', 'инге', 'исом', 'ерон', 'уэлл', 'есу', 'осс', 'хов', 'отт', 'рсом', 'ьд', 'ровой', 'йне', 'есо', 'дон', 'ук', 'ерман', 'эйн', 'ертон', 'йну', 'айл', 'пп', 'анд', 'ае', 'вска', 'эна', 'лу', 'илов', 'стер', 'льд', 'инсон', 'кины', 'ьева', 'нска', 'кса', 'йр', 'элл', 'ксо', 'енски', 'иковы', 'онова', 'йто', 'рову', 'сова', 'энд', 'ейс', 'онд', 'рдом', 'товы', 'ге', 'ль', 'монд', 'дже', 'нтон', 'рду', 'ейно', 'орт', 'ино', 'ловым', 'ррис', 'рта', 'лли', 'ндо', 'нга', 'дс', 'ерт', 'айт', 'лса', 'нская', 'овског', 'овского', 'ос', 'ворт', 'п', 'ровы', 'асов', 'нсе', 'лз', 'шев', 'тоне', 'ндом', 'лом', 'дд', 'айн', 'рес', 'СОН', 'ково', 'леру', 'ману', 'икова', 'ински', 'мэн', 'еном', 'нберг', 'пер', 'нско', 'уэр', 'ченк', 'еса', 'рто', 'ич', 'енс', 'ЕВ', 'лан', 'ллом', 'инов', 'нге', 'ллу', 'да', 'рев', 'дов', 'нев', 'йном', 'тейн', 'ян', 'цки', 'тто', 'ксон', 'овско', 'имов', 'нн', 'ИН', 'бера', 'ново', 'нсу', 'вской', 'ковой', 'аков', 'ловы', 'аева', 'ченко', 'онс', 'рг', 'нк', 'лле', 'бс', 'нову', 'эй', 'ны', 'ло', 'В', 'нсом', 'рдо', 'рда', 'ис', 'тсон', 'С', 'ере', 'нсен', 'ерсо', 'исо', 'новой', 'овский', 'аров', 'вер', 'йно', 'ерг', 'гтон', 'ингтон', 'нгтон', 'рман', 'скому', 'това', 'чев', 'филд', 'рн', 'гс', 'рсо', 'ртон', 'мон', 'маном', 'гер', 'вуд', 'ду', 'ска', 'кому', 'мс', 'ским', 'лло', 'мер', 'ена', 'де', 'елла', 'вског', 'вского', 'кинс', 'до', 'берг', 'дер', 'лова', 'исон', 'гин', 'ким', 'тта', 'дж', 'мано', 'ла', 'вско', 'ай', 'тс', 'ОВ', 'ОН', 'илд', 'ЕР', 'анова', 'стон', 'йна', 'ллер', 'мана', 'вин', 'мов', 'ерсон', 'йд', 'ьев', 'илл', 'нер', 'ил', 'йс', 'нса', 'рсон', 'кову', 'етт', 'форд', 'ево', 'новым', 'аном', 'ВА', 'эр', 'орд', 'Р', 'ве', 'дом', 'уэ', 'ену', 'уд', 'кер', 'рр', 'лев', 'нин', 'ган', 'ру', 'оне', 'сс', 'ден', 'еев', 'эм', 'нског', 'нского', 'тоном', 'ану', 'вский', 'лтон', 'ском', 'тону', 'рова', 'новы', 'тер', 'нский', 'ове', 'ину', 'ОВА', 'ог', 'тона', 'ых', 'лд', 'тоно', 'кина', 'нсо', 'йл', 'овски', 'онов', 'оу', 'евой', 'овых', 'йт', 'ным', 'ской', 'лин', 'сону', 'сов', 'ерс', 'ейн', 'сен', 'ковым', 'ана', 'ард', 'нсон', 'рс', 'з', 'ско', 'го', 'во', 'ра', 'кс', 'рт', 'лс', 'ая', 'лла', 'ская', 'аев', 'вых', 'лов', 'соном', 'ч', 'инс', 'се', 'еву', 'ров', 'евым', 'нд', 'инг', 'ого', 'бер', 'кая', 'ины', 'вски', 'не', 'нски', 'ано', 'ковы', 'нко', 'ром', 'эн', 'енк', 'соно', 'еру', 'ро', 'лер', 'евы', 'ес', 'иным', 'анов', 'ону', 'тт', 'енко', 'оном', 'ков', 'нова', 'елл', 'еро', 'нг', 'сона', 'кова', 'йн', 'рд', 'ина', 'ово', 'ског', 'ского', 'ером', 'оно', 'ман', 'кин', 'ког', 'кого', 'она', 'ера', 'сом', 'э', 'ский', 'су', 'ева', 'овой', 'кий', 'ву', 'ен', 'нс', 'Н', 'ову', 'ски', 'са', 'вой', 'г', 'лл', 'ном', 'ан', 'овым', 'тон', 'со', 'нов', 'ну', 'но', 'д', 'ом', 'овы', 'вым', 'ым', 'л', 'сон', 'ев', 'вы', 'на', 'ин', 'у', 'ва', 'р', 'о', 'ова', 'ер', 'он', 'ов', 'а', 'в', 'с', 'н']\n",
      "CPU times: user 26.3 s, sys: 110 ms, total: 26.4 s\n",
      "Wall time: 26.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "td = dict()\n",
    "idf = dict()\n",
    "for i in range(len(row_train[0])):\n",
    "    s = row_train[0][i]\n",
    "    for l in range(1,8):\n",
    "        if len(s) < l:\n",
    "            continue\n",
    "        for j in [0,1]:\n",
    "            suffx = s[-l:]\n",
    "            if j == 1 and len(suffx) > 1:\n",
    "                suffx = suffx[:-1]\n",
    "                \n",
    "            if suffx[0].isupper() and not suffx.isupper():\n",
    "                continue\n",
    "            if suffx not in td:\n",
    "                td[suffx] = 0\n",
    "                idf[suffx] = 0\n",
    "            idf[suffx] += 1\n",
    "            if row_train[1][i] == 1:\n",
    "                td[suffx] += 1\n",
    "\n",
    "tdidf = []\n",
    "s1 =  np.sum(row_train[1])\n",
    "s2 = len(row_train[1])\n",
    "alpha = s1/(s2 - s1)\n",
    "for key in td:\n",
    "    tdidf.append(((td[key] - alpha*(idf[key] - td[key])) * np.log(len(row_train[0])/idf[key]),key))\n",
    "tdidf = sorted(tdidf)\n",
    "best = [w[1] for w in tdidf[-500:]]\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 58s, sys: 2.75 s, total: 2min 1s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_suff,dum = add_strs(row_train,suffixes=best)\n",
    "test_suff,dum = add_strs(row_test, suffixes=best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101408, 73143) (101408, 2)\n",
      "CPU times: user 8.4 s, sys: 435 ms, total: 8.84 s\n",
      "Wall time: 9.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainM, testM = add_count_vectorizer_features(row_train, row_test)\n",
    "print(trainM.shape, row_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101408, 73143)\n"
     ]
    }
   ],
   "source": [
    "print(trainM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_custom_features(train, test):\n",
    "    Train = normalize(add_custom(train, (lambda s: len(s)),'_len'),'_len')\n",
    "    Test = normalize(add_custom(test, (lambda s: len(s)),'_len'),'_len')\n",
    "    Train = add_custom(Train, (lambda s: s[0].isupper()), '0_upper')\n",
    "    Test = add_custom(Test, (lambda s: s[0].isupper()), '0_upper')\n",
    "    Train = add_custom(Train, (lambda s: s[1:].islower()), '1_lower')\n",
    "    Test = add_custom(Test, (lambda s: s[1:].islower()), '1_lower')\n",
    "    Train = add_custom(Train, (lambda s: s[0].isupper() and s[1:].islower()), 'up_low')\n",
    "    Test = add_custom(Test, (lambda s: s[0].isupper() and s[1:].islower()), 'up_low')\n",
    "    Train = add_custom(Train, (lambda s: not s.isalpha()), 'trash')\n",
    "    Test = add_custom(Test, (lambda s: not s.isalpha()), 'trash')\n",
    "    Train = Train.drop([0,1],axis=1)\n",
    "    Test = Test.drop([0],axis=1)\n",
    "    if 1 in Test.columns:\n",
    "        Test = Test.drop([1],axis=1)\n",
    "    return np.array(Train,dtype=float), np.array(Test,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_FULL = sprs.hstack([trainM, sprs.coo_matrix(train_ADD), train_suff])\n",
    "test_FULL = sprs.hstack([testM, sprs.coo_matrix(test_ADD), test_suff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ского', 'ский', 'овой', 'ову', 'овым', 'овы', 'вым', 'вы', 'нов',\n",
      "       'сон', 'ев', 'ова', 'ин', 'он', 'ов', 'р', 'в', 'с', 'н', '_len',\n",
      "       '0_upper', 'up_low'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Train_d0Y.columns[best_col > 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_features_frames(train, test):\n",
    "    train_vect, test_vect = add_count_vectorizer_features(train, test)\n",
    "    train_my_f, test_my_f = add_custom_features(train, test)\n",
    "    train_suff,dum = add_strs(train,suffixes=best)\n",
    "    test_suff,dum = add_strs(test, suffixes=best)\n",
    "    Train = sprs.hstack([train_vect, sprs.coo_matrix(train_my_f), train_suff])\n",
    "    Test = sprs.hstack([test_vect, sprs.coo_matrix(test_my_f), test_suff])\n",
    "    \n",
    "#     Train, Test = train_vect, test_vect\n",
    "    return Train, Test\n",
    "\n",
    "def cross_val(Train,  clf, folds=4):\n",
    "    score = []\n",
    "    Y = Train[1]\n",
    "    for train_indices, test_indices in cross_validation.KFold(len(Y), n_folds = folds):\n",
    "        Train_train = Train.loc[train_indices]\n",
    "        Train_test = Train.loc[test_indices]\n",
    "        Train_train.index = np.arange(len(train_indices))\n",
    "        Train_test.index = np.arange(len(test_indices))\n",
    "        x_train, x_test = gen_features_frames(Train_train, Train_test)\n",
    "        y_train = Y[train_indices]\n",
    "        y_test = Y[test_indices]\n",
    "        clf.fit(sprs.coo_matrix(x_train),y_train)\n",
    "        y_pred = clf.predict_proba(sprs.coo_matrix(x_test))[:,1]\n",
    "#         y_pred = [y if y > 1e-5 else 0 for y in y_pred ]\n",
    "        score.append(roc_auc_score(y_test, y_pred))\n",
    "    return [np.mean(score), np.std(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clfs = [\n",
    "        LogisticRegression(penalty='l1',\n",
    "                    max_iter=100,\n",
    "                    C=1,\n",
    "                    class_weight='balanced',\n",
    "                    verbose=True),\n",
    "]\n",
    "\n",
    "ans = []\n",
    "for clf in clfs:\n",
    "    ans.append(cross_val(row_train, clf, 4))\n",
    "    print(ans[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calc_score(X,Y,clfs):\n",
    "    scores = []\n",
    "    for clf in clfs:\n",
    "        sc = cross_validation.cross_val_score(\n",
    "            clf, X, Y, scoring='roc_auc', cv=4, n_jobs=4)\n",
    "        scores.append((np.mean(sc), np.std(sc)))\n",
    "        print(scores[-1])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.coo.coo_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_FULL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.70097258809253615, 0.10937493326371894)\n",
      "(0.69530414874278024, 0.11139817908552929)\n",
      "(0.77365322546016835, 0.070694701270657606)\n",
      "[(0.70097258809253615, 0.10937493326371894), (0.69530414874278024, 0.11139817908552929), (0.77365322546016835, 0.070694701270657606)]\n",
      "CPU times: user 1.58 s, sys: 523 ms, total: 2.1 s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clfs = [\n",
    "    LogisticRegression(penalty='l1',class_weight='balanced',random_state=1),\n",
    "    LogisticRegression(penalty='l1',random_state=1),\n",
    "    LogisticRegression(penalty='l2',random_state=1),\n",
    "#     RandomForestClassifier(max_depth=60,n_estimators=50,n_jobs=1),\n",
    "#     RandomForestClassifier(max_depth=60,n_estimators=50,n_jobs=1,criterion='entropy')\n",
    "]\n",
    "\n",
    "scores=calc_score(train_FULL, row_train[1], clfs)\n",
    "print(scores)\n",
    "#balanced40 - 0.864 l2- 0.85\n",
    "#not_balanced 50 - 0.883, 40 -0.881 l2/300 - 0.86 60/500 - 0.884 l2/1000 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_ans(_y_test, filename):\n",
    "    print(_y_test)\n",
    "    names = np.arange(len(_y_test))\n",
    "    ans = pd.DataFrame(data=np.matrix(_y_test).T, columns=['Answer'])\n",
    "    ans = pd.concat((pd.DataFrame(names,columns=['Id']),ans),axis=1)\n",
    "    ans.to_csv(filename,index=None)\n",
    "\n",
    "def predict(clf,file,X,Y,_test,times=1):\n",
    "    pred = np.zeros(len(row_test[0]))\n",
    "    for t in range(times):\n",
    "        clf.fit(X,Y)\n",
    "        pred += clf.predict_proba(_test)[:,1]\n",
    "    pred /= times\n",
    "    save_ans(pred, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((101408, 73148), (101408, 2), (188920, 73148))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_FULL.shape, row_train.shape, test_FULL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8.38883592e-01   7.82064525e-01   5.04808748e-01 ...,   9.57928124e-02\n",
      "   1.39583881e-04   1.01367653e-04]\n",
      "CPU times: user 8.25 s, sys: 230 ms, total: 8.48 s\n",
      "Wall time: 8.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predict(\n",
    "    LogisticRegression(penalty='l1',n_jobs=1,class_weight='balanced'),\n",
    "    'countVectorizer_with_myF_all_L1_fixed_mean1',\n",
    "    train_FULL,\n",
    "    row_train[1],\n",
    "    test_FULL,\n",
    "    1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.27163323  0.18229266  0.         ...,  0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "files = [ 'countVectorizer1'\n",
    "        ]\n",
    "\n",
    "for f in files:\n",
    "    data = np.array(pd.read_csv(f)['Answer'])\n",
    "for i in range(len(data)):\n",
    "    if data[i] < 0.1:\n",
    "        data[i] = 0\n",
    "    if data[i] > 0.99:\n",
    "        data[i]  = 1\n",
    "    \n",
    "save_ans(data, 'countVectorizer1_cliped0_1_and_0_99')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.22736869,  0.10822005,  0.18498921, ...,  0.12425834,\n",
      "        0.0267048 ,  0.0267048 ]), array([ 0.31276735,  0.16688845,  0.31374668, ...,  0.11295054,\n",
      "        0.00637569,  0.01141766])]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "a[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

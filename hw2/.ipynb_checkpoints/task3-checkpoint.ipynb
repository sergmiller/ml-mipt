{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import cross_validation\n",
    "from sklearn.tree import DecisionTreeRegressor as SklearnDecisionTreeRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class DecisionTree(BaseEstimator):\n",
    "    '''\n",
    "    Simple decision tree regressor with MSE rule and random best split by one feature,\n",
    "    X and y -Features and Targets, must have numpy.ndarray class\n",
    "    n_partitions - Number of partitions in each split, n_partitions = number of values if None \n",
    "    err_f - H(R) - Inhomogeneity function\n",
    "    '''\n",
    "    class Node(object):\n",
    "        def __init__(self, X, y, err_f, n_partitions, max_depth):\n",
    "            self.isLeaf = True\n",
    "            self.err_f = err_f\n",
    "            self.max_depth = max_depth\n",
    "            self.n_partitions = n_partitions\n",
    "            if self.n_partitions:\n",
    "                self.n_partitions = max(2, self.n_partitions)\n",
    "                self.quants = np.arange(self.n_partitions)/(self.n_partitions - 1)\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "#             print('node in depth: ' + str(max_depth))\n",
    "            self.split()\n",
    "            \n",
    "        def partition_err(self, X_slice, bins):\n",
    "            Q = len(X_slice)\n",
    "            nR = np.sum(bins)\n",
    "            nL = Q - nR\n",
    "            R = self.y[bins > 0]\n",
    "            L = self.y[bins < 1]\n",
    "            \n",
    "#             print('sum bins',np.sum(bins))\n",
    "            return nL/Q*self.err_f(L, np.ones_like(L)*np.mean(L)) + nR/Q*self.err_f(R, np.ones_like(R)*np.mean(R))\n",
    "                \n",
    "        def split(self):\n",
    "            if self.max_depth == 1 or len(self.X) <= 1:\n",
    "                self.predict = np.mean(self.y)\n",
    "                return\n",
    "            self.split_err = np.inf\n",
    "            for ft in range(len(self.X[0])):\n",
    "                X_feature_slice = self.X[:,ft]\n",
    "#                 print('slice',X_feature_slice)\n",
    "                sorted_slice = np.array(list(np.sort(list(set(X_feature_slice))))[:-1])\n",
    "#                 print('sorted',sorted_slice)\n",
    "                \n",
    "                if len(sorted_slice) <= 1:\n",
    "                    continue\n",
    "#                 print('quants',np.array(self.quants * (len(sorted_slice)-1),dtype=int),len(sorted_slice))\n",
    "                if  self.n_partitions:\n",
    "                    partitions = sorted_slice[np.array(self.quants * (len(sorted_slice)-1),dtype=int)]\n",
    "                else:\n",
    "                    partitions = sorted_slice\n",
    "                    \n",
    "#                 print('part: ',partitions)\n",
    "                    \n",
    "                for bound in partitions:\n",
    "#                     print('bound',bound)\n",
    "                    bins =  (X_feature_slice > bound)\n",
    "                    error = self.partition_err(X_feature_slice, bins)\n",
    "                    if error < self.split_err:\n",
    "                        self.split_err = error\n",
    "                        self.split_bins = bins\n",
    "                        self.split_feature = ft\n",
    "                        self.split_bound = bound\n",
    "            \n",
    "            if self.split_err == np.inf:\n",
    "                self.predict = np.mean(self.y)\n",
    "                return\n",
    "            \n",
    "            self.isLeaf = False\n",
    "            \n",
    "            md = self.max_depth\n",
    "            if md:\n",
    "                md -= 1\n",
    "            self.Left = DecisionTree.Node(self.X[self.split_bins < 1], self.y[self.split_bins < 1], \n",
    "                                          self.err_f, self.n_partitions, md)\n",
    "            self.Right = DecisionTree.Node(self.X[self.split_bins > 0], self.y[self.split_bins > 0], \n",
    "                                           self.err_f, self.n_partitions, md) \n",
    "            \n",
    "    def __init__(self, err_f = mean_squared_error, n_partitions=None,max_depth=None):\n",
    "        self.err_f = err_f\n",
    "        self.max_depth = max_depth\n",
    "        self.n_partitions = n_partitions\n",
    "    def fit(self, X, y):\n",
    "        self.root = self.Node(X,y,self.err_f, self.n_partitions, self.max_depth)\n",
    "    def predict(self, X):\n",
    "        y = []\n",
    "        for x in X:\n",
    "            cur = self.root\n",
    "            aa = 0\n",
    "            while not cur.isLeaf:\n",
    "                aa += 1\n",
    "#                 print(aa)\n",
    "                if x[cur.split_feature] > cur.split_bound:\n",
    "                    cur = cur.Right\n",
    "                else:\n",
    "                    cur = cur.Left\n",
    "            y.append(cur.predict)\n",
    "        return np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def benchmark(clfr,params,hmax=5):\n",
    "    scores = []\n",
    "    \n",
    "    for h in range(1,hmax):\n",
    "        params['max_depth'] = h\n",
    "        clf = clfr(**params)\n",
    "        scores.append(np.mean(cross_validation.cross_val_score(clf,X,y,n_jobs=4,scoring=make_scorer(mean_squared_error),cv=2)))\n",
    "#         print(np.array(scores).shape)\n",
    "    plt.plot(np.arange(1,hmax),scores,label=str(clfr.__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = 20\n",
    "plt.figure(figsize=(7,5))\n",
    "benchmark(DecisionTree, {'n_partitions':10},h)\n",
    "benchmark(SklearnDecisionTreeRegressor, {'max_features':1,'random_state':1},h)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
